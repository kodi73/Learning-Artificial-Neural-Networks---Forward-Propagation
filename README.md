# Neural Network Learning Project

## Project Description

This project is a hands-on learning experience focused on understanding the fundamental concepts of neural networks. It explores the building blocks of a simple neural network, including:

- Initialization of network weights and biases.
- Computation of weighted sums at each node.
- Application of activation functions (specifically the sigmoid function) to introduce non-linearity.
- Forward propagation of inputs through the network to generate predictions.

The code demonstrates a step-by-step approach to constructing and running a basic neural network, providing a clear illustration of the underlying mathematical operations involved.

## How to Run the Code

1.  **Open in Google Colab:** This notebook is designed to be run in Google Colab. You can upload the `.ipynb` file to your Google Drive and open it with Google Colab.
2.  **Run the cells:** Execute each code cell sequentially. The notebook is structured to guide you through the process of building and running the neural network.
3.  **Explore the output:** Examine the output of each cell to understand the intermediate calculations and the final predictions of the network.

## Acknowledgements

This learning project was developed with the invaluable guidance and support of **Alex Aklson** (linkedin: [linkedin.com/in/aklson](linkedin.com/in/aklson)). His expertise and tutoring were instrumental in understanding the concepts and implementing the code.
